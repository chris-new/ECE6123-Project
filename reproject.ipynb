{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import time\n",
    "from scipy.spatial import cKDTree\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def mesh_to_point_cloud(mesh_path, num_points=1000):\n",
    "    mesh = read_mesh(mesh_path)\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=num_points)\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def read_mesh(filename:str):\n",
    "    #pcd = o3d.io.read_triangle_mesh(filename, True)\n",
    "    pcd = o3d.io.read_triangle_model(filename, True)\n",
    "    return pcd\n",
    "\n",
    "def read_point_cloud(filename:str):\n",
    "    pcd = o3d.io.read_point_cloud(filename)\n",
    "    return pcd\n",
    "\n",
    "\n",
    "def render(geometries):\n",
    "    o3d.visualization.draw_geometries(geometries)\n",
    "\n",
    "\n",
    "# side effect: will set renderer_pc's extrinsic camera\n",
    "def get_view(renderer_pc, intrinsic, model, center, eye, up=[0,1,0], extrinsic=None, img_width=400, img_height=500):\n",
    "\n",
    "\n",
    "    # grey = o3d.visualization.rendering.MaterialRecord()\n",
    "    # grey.base_color = [0.7, 0.7, 0.7, 1.0]\n",
    "    # grey.shader = \"defaultLit\"\n",
    "    \n",
    "    material = o3d.visualization.rendering.MaterialRecord()\n",
    "    # texture = np.asarray(model.colors).copy()\n",
    "    # texture = texture.astype(np.float32)\n",
    "    # texture = o3d.geometry.Image(texture)\n",
    "    # material.albedo_img = texture\n",
    "    material.aspect_ratio = 1.0\n",
    "    material.base_color = [0.7, 0.7, 0.7, 1.0]\n",
    "    material.shader = \"defaultUnlit\"\n",
    "\n",
    "\n",
    "\n",
    "    # renderer_pc.scene.scene.set_sun_light([-1, -1, -1], [1.0, 1.0, 1.0], 100000)\n",
    "    renderer_pc.scene.scene.enable_sun_light(False)\n",
    "    \n",
    "    renderer_pc.scene.set_lighting(renderer_pc.scene.LightingProfile.HARD_SHADOWS, (0, 0, 0))\n",
    "    # renderer_pc.scene.set_lighting(renderer_pc.scene.LightingProfile.NO_SHADOWS, (0, 0, 0))\n",
    "    # renderer_pc.scene.scene.enable_sun_light(True)\n",
    "\n",
    "    renderer_pc.scene.add_geometry(\"model\", model, material)\n",
    "    \n",
    "    # # just for reference \n",
    "    # axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1.0, origin=([0., 0., 0.]))\n",
    "    # renderer_pc.scene.add_geometry(\"axis\", axis, material)\n",
    "\n",
    "    \n",
    "    # for triangle meshes\n",
    "    # renderer_pc.scene.add_model(\"model\", model)\n",
    "\n",
    "    # Optionally set the camera field of view (to zoom in a bit)\n",
    "    vertical_field_of_view = 30  # between 5 and 90 degrees\n",
    "    aspect_ratio = img_width / img_height  # azimuth over elevation\n",
    "    near_plane = 0.05\n",
    "    far_plane = 50.0\n",
    "    fov_type = o3d.visualization.rendering.Camera.FovType.Vertical\n",
    "    # renderer_pc.scene.camera.set_projection(vertical_field_of_view, aspect_ratio, near_plane, far_plane, fov_type)\n",
    "    \n",
    "    renderer_pc.scene.camera.set_projection(intrinsic.intrinsic_matrix, near_plane, far_plane, img_width, img_height)\n",
    "\n",
    "    # Look at the origin from the front (along the -Z direction, into the screen), with Y as Up.\n",
    "    # camera orientation\n",
    "    # extrinsic = lookat(np.asarray(center), np.asarray(eye), np.asarray(up))\n",
    "    renderer_pc.scene.camera.look_at(center, eye, up)\n",
    "    if extrinsic is not None:\n",
    "        renderer_pc.setup_camera(intrinsic, extrinsic)\n",
    "    # renderer_pc.setup_camera(intrinsic, extrinsic)\n",
    "\n",
    "    depth_image = np.asarray(renderer_pc.render_to_depth_image(True) )\n",
    "    image = np.asarray(renderer_pc.render_to_image())\n",
    "\n",
    "\n",
    "    # plt.imshow(depth_image)\n",
    "    renderer_pc.scene.remove_geometry(\"model\")\n",
    "    # renderer_pc.scene.remove_geometry(\"axis\")\n",
    "    return (image, depth_image, renderer_pc.scene.camera.get_view_matrix())\n",
    "\n",
    "def recenter_model(model):\n",
    "    mean_cov = model.compute_mean_and_covariance()\n",
    "    mean = mean_cov[0]\n",
    "    covariance_matrix = mean_cov[1]\n",
    "\n",
    "    eigen_values, eigen_vectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    # 特征向量与特征值关联，并按特征值排序（特征值最大的对应主要的方向）\n",
    "    eig_index = np.argsort(eigen_values)[::-1]\n",
    "    principal_axes = eigen_vectors[:, eig_index]\n",
    "    # principal_axes = principal_axes.transpose()\n",
    "\n",
    "    # the first axis of pca should be y axis for a human\n",
    "    principal_axes[:,[0,1]] = principal_axes[:,[1,0]]\n",
    "\n",
    "    if principal_axes[:, 0] [0]< 0:\n",
    "        principal_axes[:,0]*= -1\n",
    "    if principal_axes[:,1][1] < 0:\n",
    "        principal_axes[:,1]*= -1\n",
    "    if principal_axes[:,2][2] < 0:\n",
    "        principal_axes[:,2]*= -1\n",
    "    # print(principal_axes)\n",
    "\n",
    "    # new_z_axis = np.array([principal_axes[:,2][0], 0, principal_axes[:,2][1]])\n",
    "\n",
    "    # z_axis = np.array([0, 0, 1])\n",
    "\n",
    "    # rotation_axis = np.cross(z_axis, new_z_axis)\n",
    "    # # print(rotation_axis)\n",
    "\n",
    "    # # 计算旋转角度（dot product和arccos）\n",
    "    # cos_theta = np.dot(z_axis, new_z_axis) / (np.linalg.norm(z_axis) * np.linalg.norm(new_z_axis))\n",
    "    # angle = np.arccos(cos_theta)\n",
    "\n",
    "    # # 计算旋转矩阵（Rodrigues' rotation formula）\n",
    "    # K = np.array([\n",
    "    #     [0, -rotation_axis[2], rotation_axis[1]],\n",
    "    #     [rotation_axis[2], 0, -rotation_axis[0]],\n",
    "    #     [-rotation_axis[1], rotation_axis[0], 0]\n",
    "    # ])\n",
    "    # identity_matrix = np.eye(3)\n",
    "    # rotation_matrix = identity_matrix + np.sin(-angle) * K + (1 - np.cos(-angle)) * (K @ K)\n",
    "\n",
    "    # model.rotate(rotation_matrix, center=mean)\n",
    "    model.rotate(principal_axes.transpose(), center=mean)\n",
    "\n",
    "    # mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1.5, origin=mean)\n",
    "    # mesh_frame.rotate(principal_axes, center=mean)\n",
    "    # coorinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1, origin=[0., 0., 0.])\n",
    "    # o3d.visualization.draw_geometries([model, mesh_frame,coorinate ] )\n",
    "    \n",
    "def lookat(center, eye, up):\n",
    "    f = (eye - center)\n",
    "    f /= np.linalg.norm(f)\n",
    "    \n",
    "    r = np.cross(up, f)\n",
    "    r /= np.linalg.norm(r)\n",
    "    \n",
    "    u = np.cross(f, r)\n",
    "    u /= np.linalg.norm(u)\n",
    "\n",
    "    view_matrix = np.eye(4)\n",
    "    view_matrix[:3, :3] = np.column_stack((r, u, -f))\n",
    "    view_matrix[:3, 3] = -np.dot(np.column_stack((r, u, -f)), eye)\n",
    "    \n",
    "    return view_matrix\n",
    "\n",
    "\n",
    "def flip(matrix):\n",
    "    result = np.copy(matrix)\n",
    "    result[1:3,:] = -1 * result[1:3,:]\n",
    "    return result\n",
    "\n",
    "\n",
    "def rgbd_to_pointcloud(rgbd, intrinsic, extrinsic_camera):\n",
    "    # extrinsic_camera = np.array(extrinsic_camera)\n",
    "    # extrinsic_camera = np.linalg.inv(extrinsic_camera)\n",
    "    pcd =  o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic, flip(extrinsic_camera))\n",
    "    # Flip it, otherwise the pointcloud will be upside down\n",
    "    #pcd.transform([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "    return pcd\n",
    "\n",
    "def rgbd_to_pointcloud2(rgbd, intrinsic, extrinsic_path):\n",
    "    extrinsic  = np.load(extrinsic_path).astype(np.float32)\n",
    "    pcd =  o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic, flip(extrinsic))\n",
    "    return pcd\n",
    "def downsample_rescale(pcd, voxel_size=0.00001, scale=10000):\n",
    "    downsampled_pc = pcd.voxel_down_sample(voxel_size)\n",
    "    # use mean as the center for now\n",
    "    a1 = np.asarray(downsampled_pc.points)\n",
    "    scaled_downsampled_pc = downsampled_pc.scale(scale, a1.mean(0))\n",
    "    return scaled_downsampled_pc\n",
    "\n",
    "\n",
    "def downsample(pcd, voxel_size=0.00001):\n",
    "    downsampled_pc = pcd.voxel_down_sample(voxel_size)\n",
    "    return downsampled_pc\n",
    "\n",
    "\n",
    "def read_segmentation(file_name, depth):\n",
    "    # for read npy files\n",
    "    rgb = np.load(file_name).astype(np.uint8)\n",
    "    rgb = o3d.geometry.Image(rgb)\n",
    "    ## for read image files\n",
    "    #rgb = o3d.io.read_image(file_name)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        rgb, o3d.geometry.Image(depth), convert_rgb_to_intensity=False, depth_scale=1)\n",
    "    return rgbd_image\n",
    "\n",
    "def read_segmentation2(view_path, depth_path):\n",
    "    # for read npy files\n",
    "    rgb = np.load(view_path).astype(np.uint8)\n",
    "    rgb = o3d.geometry.Image(rgb)\n",
    "    depth = np.load(depth_path).astype(np.float32)\n",
    "    ## for read image files\n",
    "    #rgb = o3d.io.read_image(file_name)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        rgb, o3d.geometry.Image(depth), convert_rgb_to_intensity=False, depth_scale=1)\n",
    "    return rgbd_image\n",
    "\n",
    "def read_logits(view_path, depth_path):\n",
    "    # for read npy files\n",
    "    rgb = np.load(view_path).astype(np.float32)\n",
    "    rgb = o3d.geometry.Image(rgb)\n",
    "    depth = np.load(depth_path).astype(np.float32)\n",
    "    ## for read image files\n",
    "    #rgb = o3d.io.read_image(file_name)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        rgb, o3d.geometry.Image(depth), convert_rgb_to_intensity=False, depth_scale=1)\n",
    "    return rgbd_image\n",
    "\n",
    "\n",
    "\n",
    "def project(model_path, centers, eyes, renderer_pc, intrinsic, img_width, img_height):\n",
    "    model = read_point_cloud(model_path)\n",
    "    #IDEA recenter and rescale the model \n",
    "    points = np.asarray(model.points)\n",
    "    points \n",
    "    points -= points.mean(0)\n",
    "    model.transform(np.array([[1,0,0,0], \n",
    "                            [0,1,0,0],\n",
    "                            [0,0,1,0],\n",
    "                            [0,0,0,1]]))\n",
    "    recenter_model(model)\n",
    "\n",
    "    Image = []\n",
    "    Depth = []\n",
    "    Extrinsic = []\n",
    "    for i in range(len(eyes)):\n",
    "        image, depth, extrinsic = get_view(renderer_pc, intrinsic, model, center=centers[i], eye=eyes[i], up=[0,1,0], img_width=img_width, img_height=img_height)\n",
    "        Image.append(image)\n",
    "        Depth.append(depth)\n",
    "        Extrinsic.append(extrinsic)\n",
    "    return Image, Depth, Extrinsic\n",
    "\n",
    "def reproject(Masks, Depth, intrinsic, Extrinsic):\n",
    "    # Pcd = []\n",
    "    Pcd = o3d.geometry.PointCloud()\n",
    "    for i in range(len(Masks)):\n",
    "        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "            o3d.geometry.Image(Masks[i].astype(np.float32)), o3d.geometry.Image(Depth[i]), convert_rgb_to_intensity=False, depth_scale=1)\n",
    "        pcd = rgbd_to_pointcloud(rgbd_image, intrinsic, Extrinsic[i])\n",
    "        Pcd = pcd + Pcd\n",
    "    return Pcd\n",
    "\n",
    "def save_pcd(pcd, file_path):\n",
    "    o3d.io.write_point_cloud(file_path, pcd)\n",
    "\n",
    "def knn_for_all_conflict_points(Pcd):\n",
    "    K = 100\n",
    "\n",
    "    Pcd_points = np.asarray(Pcd.points)\n",
    "    Pcd_colors = np.asarray(Pcd.colors)\n",
    "    # knn for one point\n",
    "    def knn(location):\n",
    "        points = Pcd_points\n",
    "        distances = np.linalg.norm(points - location, ord=2, axis=1)\n",
    "        inds = np.argsort(distances)[:K]\n",
    "        labels = Pcd_colors[inds]\n",
    "        unique_labels, counts = np.unique(labels, axis=0, return_counts=True)\n",
    "        return unique_labels[np.argsort(counts)[-1]]\n",
    "    \n",
    "    uniques, counts = np.unique(Pcd_points, axis=0, return_counts=True)\n",
    "    duplicate_points = uniques[counts > 1]\n",
    "    all_inds = np.arange(0, len(Pcd_points))\n",
    "    print(\"Find {} duplicate points\".format(len(duplicate_points)))\n",
    "    for point in duplicate_points:\n",
    "        inds = all_inds[np.all(Pcd_points == point, axis=1)]\n",
    "        colors = Pcd_colors[inds]\n",
    "        if len(np.unique(colors, axis=0)) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            label = knn(point)\n",
    "        Pcd_colors[inds][:] = label\n",
    "    \n",
    "    pcd_ret = o3d.geometry.PointCloud()\n",
    "    pcd_ret.points = o3d.utility.Vector3dVector(Pcd_points)\n",
    "    pcd_ret.colors = o3d.utility.Vector3dVector(Pcd_colors)\n",
    "\n",
    "    return pcd_ret\n",
    "    \n",
    "def list_all_files(directory):\n",
    "    all_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            all_files.append(os.path.join(dirpath, filename))\n",
    "    return all_files\n",
    "\n",
    "def knn_with_confidence(K, location, tree, colors, logits, unique_labels, useMean=True):\n",
    "        _, inds = tree.query(location, k=K)\n",
    "        labels = colors[inds]\n",
    "        confidentials = logits[inds]\n",
    "        results = np.zeros((unique_labels.shape[0],))\n",
    "        \n",
    "        for i, unique_label in enumerate(unique_labels):\n",
    "        # Find all rows in labels that match the current unique_label\n",
    "            matches = np.all(labels == unique_label, axis=1)\n",
    "            if np.any(matches):  # Check if there are any matches\n",
    "                # sum -> mean\n",
    "                if useMean:\n",
    "                    results[i] = np.mean(confidentials[matches])\n",
    "                else:\n",
    "                    results[i] = np.sum(confidentials[matches])/len(inds)\n",
    "            else:\n",
    "                results[i] = 0  # or some other value indicating no matches\n",
    "\n",
    "        if np.all(unique_labels[np.argmax(results)] == [0,0,0]) and results[np.argsort(results)[-2]] > 0.1:\n",
    "            result = unique_labels[np.argsort(results)[-2]]\n",
    "        else:\n",
    "            result = unique_labels[np.argmax(results)]\n",
    "        # result = unique_labels[np.argmax(results)]\n",
    "        # unique_labels, counts = np.unique(labels, axis=0, return_counts=True)\n",
    "        # result = unique_labels[np.argsort(counts)[-1]]\n",
    "        # #IDEA assumption for human models: no backgrounds\n",
    "        # if (np.array_equal(result, background_label)):\n",
    "        #     # if there is other choice\n",
    "        #     if len(unique_labels) > 1:\n",
    "        #         result = unique_labels[np.argsort(counts)[-2]]\n",
    "        #     # choose the cloest point \n",
    "        #     else:\n",
    "        #         distances, inds = tree.query(location, k=4000)\n",
    "        #         non_background_distances = []\n",
    "        #         for i in range(4000):\n",
    "        #             if not np.array_equal(colors[inds[i]], background_label):\n",
    "        #                 non_background_distances.append((distances[i], colors[inds[i]]))\n",
    "        #         if non_background_distances:\n",
    "        #             result = min(non_background_distances, key=lambda x: x[0])[1]\n",
    "        return result\n",
    "    \n",
    "def knn_with_confidence_within_radius(radius, location, tree, colors, logits, unique_labels, useMean = True):\n",
    "    # _, inds = tree.query(location, k=K)\n",
    "    inds = tree.query_ball_point(location, radius)\n",
    "    # [k, inds, _]=tree.search_radius_vector_3d(location, 0.1)\n",
    "    labels = colors[inds]\n",
    "    confidentials = logits[inds]\n",
    "    results = np.zeros((unique_labels.shape[0],))\n",
    "    \n",
    "    # for label, confidential in zip(labels, confidentials):\n",
    "    #     # Find the index of the label in unique_labels\n",
    "    #     idx = np.where(np.all(unique_labels == label, axis=1))[0]\n",
    "    #     if idx.size > 0:\n",
    "    #         results[idx[0]] += confidential[0]\n",
    "    for i, unique_label in enumerate(unique_labels):\n",
    "    # Find all rows in labels that match the current unique_label\n",
    "        matches = np.all(labels == unique_label, axis=1)\n",
    "        if np.any(matches):  # Check if there are any matches\n",
    "            # Sum the corresponding confidential values\n",
    "            if useMean:\n",
    "                results[i] = np.mean(confidentials[matches])\n",
    "            else:\n",
    "                results[i] = np.sum(confidentials[matches])/len(inds)\n",
    "        else:\n",
    "            results[i] = 0  # or some other value indicating no matches\n",
    "    if np.all(unique_labels[np.argmax(results)] == [0,0,0]) and results[np.argsort(results)[-2]] > 0.1:\n",
    "            result = unique_labels[np.argsort(results)[-2]]\n",
    "    else:\n",
    "        result = unique_labels[np.argmax(results)]\n",
    "    # result = unique_labels[np.argmax(results)]\n",
    "        # print(results[i])\n",
    "    # print(results)\n",
    "    # if unique_labels[np.argmax(results)] == [0,0,0]:\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    return result\n",
    "    \n",
    "def knn(K, location, tree, colors):\n",
    "    _, inds = tree.query(location, k=K)\n",
    "    labels = colors[inds]\n",
    "\n",
    "    unique_labels, counts = np.unique(labels, axis=0, return_counts=True)\n",
    "    result = unique_labels[np.argsort(counts)[-1]]\n",
    "\n",
    "    return result\n",
    "\n",
    "def knn_with_confidence_within_radius_weighted_mean_count(radius, location, tree, colors, logits, unique_labels, weight=0.7):\n",
    "    # _, inds = tree.query(location, k=K)\n",
    "    inds = tree.query_ball_point(location, radius)\n",
    "    total = len(inds)\n",
    "    # [k, inds, _]=tree.search_radius_vector_3d(location, 0.1)\n",
    "    labels = colors[inds]\n",
    "    confidentials = logits[inds]\n",
    "    results = np.zeros((unique_labels.shape[0],))\n",
    "    \n",
    "    # for label, confidential in zip(labels, confidentials):\n",
    "    #     # Find the index of the label in unique_labels\n",
    "    #     idx = np.where(np.all(unique_labels == label, axis=1))[0]\n",
    "    #     if idx.size > 0:\n",
    "    #         results[idx[0]] += confidential[0]\n",
    "    for i, unique_label in enumerate(unique_labels):\n",
    "    # Find all rows in labels that match the current unique_label\n",
    "        matches = np.all(labels == unique_label, axis=1)\n",
    "        if np.any(matches):  # Check if there are any matches\n",
    "            # Sum the corresponding confidential values\n",
    "            \n",
    "                results[i] = weight * np.mean(confidentials[matches]) + (1-weight) * confidentials[matches].shape[0]/total\n",
    "            \n",
    "        else:\n",
    "            results[i] = 0  # or some other value indicating no matches\n",
    "    if np.all(unique_labels[np.argmax(results)] == [0,0,0]) and results[np.argsort(results)[-2]] > 0.1:\n",
    "            result = unique_labels[np.argsort(results)[-2]]\n",
    "    else:\n",
    "        result = unique_labels[np.argmax(results)]\n",
    "    return result\n",
    "\n",
    "def knn_with_confidence_weighted_mean_count(K, location, tree, colors, logits, unique_labels, weight=0.7):\n",
    "        _, inds = tree.query(location, k=K)\n",
    "        \n",
    "        labels = colors[inds]\n",
    "        confidentials = logits[inds]\n",
    "        results = np.zeros((unique_labels.shape[0],))\n",
    "        \n",
    "        for i, unique_label in enumerate(unique_labels):\n",
    "        # Find all rows in labels that match the current unique_label\n",
    "            matches = np.all(labels == unique_label, axis=1)\n",
    "            if np.any(matches):  # Check if there are any matches\n",
    "                # sum -> mean\n",
    "                 results[i] = weight * np.mean(confidentials[matches]) + (1-weight) * confidentials[matches].shape[0]/len(inds)\n",
    "            else:\n",
    "                results[i] = 0  # or some other value indicating no matches\n",
    "\n",
    "        if np.all(unique_labels[np.argmax(results)] == [0,0,0]) and results[np.argsort(results)[-2]] > 0.1:\n",
    "            result = unique_labels[np.argsort(results)[-2]]\n",
    "        else:\n",
    "            result = unique_labels[np.argmax(results)]\n",
    "\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# files = list_all_files()\n",
    "models = [ '/home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply',\n",
    "          '/home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply']\n",
    "intrinsic =  o3d.camera.PinholeCameraIntrinsic(\n",
    "        o3d.camera.PinholeCameraIntrinsicParameters.Kinect2ColorCameraDefault)\n",
    "class AnyObject:\n",
    "    pass\n",
    "args = AnyObject() \n",
    "args.mask_input_path = '/home/demoy/3dProjection/cdcl_output'\n",
    "args.depth_input_path = '/home/demoy/3dProjection/depths'\n",
    "args.extrinsic_input_path = '/home/demoy/3dProjection/extrinsics'\n",
    "args.confidence_input_path = '/home/demoy/3dProjection/segs'\n",
    "args.num_views = 10\n",
    "args.k = 100\n",
    "args.radius = 0.05\n",
    "args.smooth = 100\n",
    "args.output_path = '/home/demoy/3dProjection/confidence_search'\n",
    "\n",
    "#part_ids = [ 0,  2,  4,  5,  6,  8, 13, 14, 16, 17, 18, 19, 20, 21, 24]\n",
    "# the order is: (left right flipped)\n",
    "# background, head, torso, left upper arm ,right upper arm, left forearm, right forearm,\n",
    "#  left hand, right hand, left thigh, right thigh, left shank, right shank, left foot, right foot\n",
    "part_ids = [0, 13, 2, 5, 8, 19, 20, 4, 24, 18, 6, 21, 16, 14, 17]\n",
    "\n",
    "r_chan = np.array([0, 127, 255, 255, 255, 127, 255, 127, 0, 0, 0, 0, 127, 255, 255])\n",
    "g_chan = np.array( [0, 127, 0, 127, 255, 0, 0, 127, 255, 0, 255, 127, 255, 127, 255])\n",
    "b_chan = np.array( [0, 127, 0, 0, 0, 255, 255, 0, 255, 255, 0, 255, 127, 127, 127])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.558004 1.999462 0.704354]\n",
      "[0.88784  1.999873 0.942558]\n"
     ]
    }
   ],
   "source": [
    "# model size\n",
    "for model in models:\n",
    "    pcd = read_point_cloud(model)\n",
    "    obox = pcd.get_axis_aligned_bounding_box()\n",
    "    print(obox.max_bound - obox.min_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test radius size \n",
    "model_point_cloud = read_point_cloud(f'/home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply')\n",
    "points = np.asarray(model_point_cloud.points)\n",
    "points \n",
    "points -= points.mean(0)\n",
    "model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                    [0,1,0,0],\n",
    "                    [0,0,1,0],\n",
    "                    [0,0,0,1]]))\n",
    "recenter_model(model_point_cloud)\n",
    "\n",
    "sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.07, resolution=30)\n",
    "sphere.translate((-0.4,0.5,0))\n",
    "render([model_point_cloud, o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0]), sphere])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results\n",
    "t = read_point_cloud(f'frame_01141.ply')\n",
    "render([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_seg_combine_channel(human_seg_split_map):\n",
    "    r_chan_seg = np.add.reduce(human_seg_split_map * np.array(r_chan), 2)\n",
    "    g_chan_seg = np.add.reduce(human_seg_split_map * np.array(g_chan), 2)\n",
    "    b_chan_seg = np.add.reduce(human_seg_split_map * np.array(b_chan), 2)\n",
    "    return np.stack([b_chan_seg, g_chan_seg, r_chan_seg], axis=-1).astype(np.uint8)\n",
    "\n",
    "def human_seg_combine_argmax(human_seg_argmax_map):\n",
    "    onehot = np.stack([(human_seg_argmax_map == i).astype(np.uint8) for i in range(15)], axis=-1)\n",
    "    return human_seg_combine_channel(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks= [500, 600, 700, 800, 900, 1000]\n",
    "# ks=[500]\n",
    "dis = [0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "history_time = []\n",
    "for k in ks:\n",
    "    \n",
    "    for d in dis:\n",
    "        args.radius = d\n",
    "        print('set radius to ', d)\n",
    "        \n",
    "        for model in models:\n",
    "            start_time = time.time()\n",
    "            print(\"Processsing model {}\".format(model))\n",
    "            id = model.split(os.sep)[-2]\n",
    "            model_point_cloud = read_point_cloud(model)\n",
    "            points = np.asarray(model_point_cloud.points)\n",
    "            points \n",
    "            points -= points.mean(0)\n",
    "            model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                                [0,1,0,0],\n",
    "                                [0,0,1,0],\n",
    "                                [0,0,0,1]]))\n",
    "            recenter_model(model_point_cloud)\n",
    "            ############ 2D to 3D Reprojection #############\n",
    "            \n",
    "            pcds = []\n",
    "            confidences = []\n",
    "            for i in range(10):\n",
    "                # idea: reconstruct a point cloud, whose color will be index to an array containing \n",
    "                # all pixel labels/confidence\n",
    "                view_path = os.path.join(args.mask_input_path, f\"{id}_image{i+1}_cdcl_segmask.npy\")\n",
    "                logit_path = os.path.join(args.confidence_input_path, f'{id}_image{i+1}_cdcl_seg.npy')\n",
    "                depth_path = os.path.join(args.depth_input_path, f\"{id}_depth{i+1}.npy\")\n",
    "                extrinsic_path = os.path.join(args.extrinsic_input_path, f\"{id}_extrinsic{i+1}.npy\")\n",
    "                \n",
    "                rgb = np.load(view_path).astype(np.uint8)\n",
    "                depth = np.load(depth_path).astype(np.float32)\n",
    "                extrinsic = np.load(extrinsic_path).astype(np.float32)\n",
    "                # shape(H*W*15 for cdcl)\n",
    "                confidence = np.load(logit_path).astype(np.float32)\n",
    "                # extract height and width i.e number of pixels\n",
    "                shape = rgb.shape[:2]\n",
    "                # build the index array, for different views, just continue extend the index\n",
    "                # read open3d api, the create_from_color_and_depth has some limitation on the \n",
    "                # conbination of data type and color channel, so have to make the index 4 byte data type\n",
    "                # error: because of the precision of floating numbers, index are not unique\n",
    "                index = np.arange(i*shape[0]*shape[1], (i+1)*shape[0]*shape[1]).astype(np.float32)\n",
    "                # reshape to the shape as the depth map\n",
    "                index = np.reshape(index, (shape))\n",
    "                \n",
    "                rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "                    o3d.geometry.Image(index), o3d.geometry.Image(depth), convert_rgb_to_intensity=False, depth_scale=1)\n",
    "                \n",
    "                pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic, flip(extrinsic), False)\n",
    "                \n",
    "                \n",
    "                pcds.append(pcd)\n",
    "                confidences.append(confidence.reshape((shape[0]*shape[1],confidence.shape[-1])))\n",
    "            # assert(len(pcds) == args.num_views)\n",
    "            \n",
    "            Pcd_merged = (reduce(lambda x, y: x + y, pcds))\n",
    "\n",
    "\n",
    "            confidences = np.array(confidences)\n",
    "            confidences = np.reshape(confidences,(len(pcds)*shape[0]*shape[1], confidence.shape[-1]))\n",
    "            \n",
    "            \n",
    "            seg_points = np.asarray(Pcd_merged.points)\n",
    "            tree = cKDTree(seg_points)\n",
    "\n",
    "            index = np.asarray(Pcd_merged.colors)\n",
    "\n",
    "            # each index should be unique\n",
    "            assert(seg_points.shape[0] == np.unique(seg_points,axis=0).shape[0])\n",
    "            assert(index.shape[0] == np.unique(index,axis=0).shape[0])\n",
    "\n",
    "            points = np.asarray(model_point_cloud.points)\n",
    "            \n",
    "            labels = []\n",
    "            for point in tqdm(points, desc=\"Assign Labels\", unit=\"point\") :\n",
    "                _, inds = tree.query(point, k=500)\n",
    "                \n",
    "                assert(inds.shape[0] == np.unique(inds,axis=0).shape[0])\n",
    "                # print(inds)\n",
    "                # inds = tree.query_ball_point(location, radius)\n",
    "                knn_index = index[inds,0].astype(int)\n",
    "                # shape(K*15)\n",
    "                knn_confidences = confidences[knn_index]\n",
    "                \n",
    "                # compute distance matrix\n",
    "                distance = np.sqrt(np.sum((seg_points[inds]-point)**2,axis=-1))\n",
    "                # print(distance)\n",
    "                assert(distance.shape==inds.shape)\n",
    "                \n",
    "                # filter points that is too far\n",
    "                knn_confidences_within_distance = knn_confidences[distance < 0.07]\n",
    "                \n",
    "                # todo: deal with empty knn_confidences_within_distance\n",
    "                \n",
    "                # merge and sort the result to get labels' mean confidence (1*15 for cdcl)\n",
    "                labels_mean = np.mean(knn_confidences_within_distance,axis=0)\n",
    "                \n",
    "                seg_argmax = np.argmax(labels_mean, axis=-1)\n",
    "                seg_max = np.max(labels_mean, axis=-1)\n",
    "                \n",
    "                # seg_max_thres = (seg_max > 0.1).astype(np.uint8)\n",
    "                # seg_argmax *= seg_max_thres\n",
    "                \n",
    "                result = seg_argmax\n",
    "\n",
    "                if seg_argmax==0:\n",
    "                    if(labels_mean[np.argsort(labels_mean)[-2]]/seg_max > 0.5):\n",
    "                        result = np.argsort(labels_mean)[-2]\n",
    "                elif seg_max < 0.1:\n",
    "                    result = 0\n",
    "                labels.append( result)\n",
    "            \n",
    "            labels_stacked = np.array(labels).astype(np.uint8)\n",
    "            \n",
    "            # assign colors based on label index\n",
    "            colors_values = np.vstack((b_chan[labels_stacked], g_chan[labels_stacked], r_chan[labels_stacked])).T\n",
    "            pcd_result = o3d.geometry.PointCloud()\n",
    "            pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "            pcd_result.colors = o3d.utility.Vector3dVector(colors_values)\n",
    "            render([pcd_result])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set k to 1000\n",
      "set radius to  0.1\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m extrinsic \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(extrinsic_path)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# shape(H*W*15 for cdcl)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m confidence \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogit_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# extract height and width i.e number of pixels\u001b[39;00m\n\u001b[1;32m     45\u001b[0m shape \u001b[38;5;241m=\u001b[39m rgb\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/open3d/lib/python3.8/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/miniconda3/envs/open3d/lib/python3.8/site-packages/numpy/lib/format.py:802\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _isfileobj(fp):\n\u001b[1;32m    801\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# current method!\n",
    "ks= [1000,1200,1400, 1600, 1800, 2000]\n",
    "# ks=[500]\n",
    "dis = [0.1, 0.11]\n",
    "history_time = []\n",
    "for k in ks:\n",
    "    args.k = k\n",
    "    print(f'set k to {k}')\n",
    "    for d in dis:\n",
    "        args.radius = d\n",
    "        print('set radius to ', d)\n",
    "        \n",
    "        for model in models:\n",
    "            start_time = time.time()\n",
    "            print(\"Processsing model {}\".format(model))\n",
    "            id = model.split(os.sep)[-2]\n",
    "            model_point_cloud = read_point_cloud(model)\n",
    "            points = np.asarray(model_point_cloud.points)\n",
    "            points -= points.mean(0)\n",
    "            model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                                [0,1,0,0],\n",
    "                                [0,0,1,0],\n",
    "                                [0,0,0,1]]))\n",
    "            recenter_model(model_point_cloud)\n",
    "            ############ 2D to 3D Reprojection #############\n",
    "            \n",
    "            pcds = []\n",
    "            confidences = []\n",
    "            for i in range(10):\n",
    "                # idea: reconstruct a point cloud using all pixels no matter the depths are valid or not\n",
    "                # from the source code, the point list is of the order of the image raw by raw. So the point list\n",
    "                # of the point cloud can be mapped to pixel confidence without other data structure\n",
    "                #\n",
    "                view_path = os.path.join(args.mask_input_path, f\"{id}_image{i+1}_cdcl_segmask.npy\")\n",
    "                logit_path = os.path.join(args.confidence_input_path, f'{id}_image{i+1}_cdcl_seg.npy')\n",
    "                depth_path = os.path.join(args.depth_input_path, f\"{id}_depth{i+1}.npy\")\n",
    "                extrinsic_path = os.path.join(args.extrinsic_input_path, f\"{id}_extrinsic{i+1}.npy\")\n",
    "                \n",
    "                rgb = np.load(view_path).astype(np.uint8)\n",
    "                depth = np.load(depth_path).astype(np.float32)\n",
    "                extrinsic = np.load(extrinsic_path).astype(np.float32)\n",
    "                # shape(H*W*15 for cdcl)\n",
    "                confidence = np.load(logit_path).astype(np.float32)\n",
    "                # extract height and width i.e number of pixels\n",
    "                shape = rgb.shape[:2]\n",
    "                \n",
    "                pcd = o3d.geometry.PointCloud.create_from_depth_image(o3d.geometry.Image(depth), intrinsic, flip(extrinsic), depth_scale=1, project_valid_depth_only=False)\n",
    "\n",
    "                pcds.append(pcd)\n",
    "                \n",
    "                # # check for pcd gotten from depth image\n",
    "                # seg_points = np.asarray(pcd.points)\n",
    "                # # get index of points with valid depth value\n",
    "                # valid_points_index = np.where(~np.any(np.isnan(seg_points), axis=1))[0]\n",
    "                # valid_points = seg_points[valid_points_index]\n",
    "                # pcd_result = o3d.geometry.PointCloud()\n",
    "                # pcd_result.points = o3d.utility.Vector3dVector(valid_points)\n",
    "                # render([pcd_result])\n",
    "                \n",
    "                confidences.append(confidence.reshape((shape[0]*shape[1],confidence.shape[-1])))\n",
    "            \n",
    "            Pcd_merged = (reduce(lambda x, y: x + y, pcds))\n",
    "\n",
    "            \n",
    "            confidences = np.array(confidences)\n",
    "            # make all confidences from all views a 1-d array to have a one-to-one mapping to the point list in the point cloud\n",
    "            confidences = np.reshape(confidences,(len(pcds)*shape[0]*shape[1], confidence.shape[-1]))\n",
    "            \n",
    "            \n",
    "            seg_points = np.asarray(Pcd_merged.points)\n",
    "\n",
    "            # get index of points with valid depth value\n",
    "            valid_points_index = np.where(~np.any(np.isnan(seg_points), axis=1))[0]\n",
    "            valid_points = seg_points[valid_points_index]\n",
    "            # build tree with valid points\n",
    "            tree = cKDTree(valid_points)\n",
    "\n",
    "            points = np.asarray(model_point_cloud.points)\n",
    "            \n",
    "            labels = []\n",
    "            for point in tqdm(points, desc=\"Assign Labels\", unit=\"point\") :\n",
    "                _, inds = tree.query(point, k=args.k)\n",
    "                \n",
    "                # inds2 = tree.query_ball_point(point, args.radius)\n",
    "                # intersection = np.intersect1d(inds, inds2)\n",
    "                # if intersection.shape[0] == 0:\n",
    "                #     result = 0\n",
    "                #     labels.append( result)\n",
    "                #     continue\n",
    "                \n",
    "                # get confidence using index in all points\n",
    "                knn_index = valid_points_index[inds].astype(int)\n",
    "                # shape(K*15)\n",
    "                knn_confidences = confidences[knn_index]\n",
    "                \n",
    "                knn_confidences_within_distance = knn_confidences\n",
    "                \n",
    "                \n",
    "                # compute distance matrix of valid points to the target point\n",
    "                distance = np.sqrt(np.sum((valid_points[inds]-point)**2,axis=-1))\n",
    "                # print(distance)\n",
    "                assert(distance.shape==inds.shape)\n",
    "                \n",
    "                # filter points that is too far\n",
    "                knn_confidences_within_distance = knn_confidences[distance <= args.radius]\n",
    "                \n",
    "                # deal with empty knn_confidences_within_distance\n",
    "                if knn_confidences_within_distance.shape[0] == 0:\n",
    "                    result = 0\n",
    "                    labels.append( result)\n",
    "                    continue\n",
    "                # merge and sort the result to get labels' mean confidence (1*15 for cdcl)\n",
    "                labels_mean = np.mean(knn_confidences_within_distance,axis=0)\n",
    "                \n",
    "                seg_argmax = np.argmax(labels_mean, axis=-1)\n",
    "                seg_max = np.max(labels_mean, axis=-1)\n",
    "                \n",
    "                \n",
    "                result = seg_argmax\n",
    "                # background thresholding\n",
    "                if seg_argmax==0:\n",
    "                    if(labels_mean[np.argsort(labels_mean)[-2]]/seg_max > 0.5):\n",
    "                        result = np.argsort(labels_mean)[-2]\n",
    "                elif seg_max < 0.1:\n",
    "                    result = 0\n",
    "                labels.append( result)\n",
    "            \n",
    "            labels_stacked = np.array(labels).astype(np.uint8)\n",
    "            \n",
    "            # assign colors based on label index\n",
    "            # open3d point cloud colors should be normalized\n",
    "            colors_values = np.vstack((b_chan[labels_stacked], g_chan[labels_stacked], r_chan[labels_stacked])).T/255\n",
    "            pcd_result = o3d.geometry.PointCloud()\n",
    "            assert(colors_values.shape[0] == points.shape[0])\n",
    "            pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "            pcd_result.colors = o3d.utility.Vector3dVector(colors_values)\n",
    "            # render([pcd_result])\n",
    "            \n",
    "            # smoothing\n",
    "            points = np.asarray(pcd_result.points)\n",
    "            seg_colors = np.asarray(pcd_result.colors)\n",
    "            tree = cKDTree(points)\n",
    "            colors = []\n",
    "            for point in tqdm(points, desc=\"Processing\", unit=\"point\") :\n",
    "                color = knn(args.smooth, point, tree, seg_colors)\n",
    "                # break\n",
    "                colors.append( color)\n",
    "                \n",
    "            colors_stacked = np.vstack(colors)\n",
    "\n",
    "            pcd_result = o3d.geometry.PointCloud()\n",
    "            pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "            pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            time_used = (int) (end_time - start_time)\n",
    "            print('time used:', time_used)\n",
    "            # render([pcd_result])\n",
    "            path = os.path.join(args.output_path, 'all_seg')\n",
    "            # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "            o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{args.k}_{args.radius}_{args.smooth}_result_{time_used}.ply'),pcd_result )\n",
    "            print(f\"{id} result point cloud output to {os.path.join(path,f'{id}_cdcl_pcd_{args.k}_{args.radius}_{args.smooth}_result_{time_used}.ply')}\")\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set radius to  0.03\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels:   0%|          | 3586/799964 [00:01<04:45, 2788.88point/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m colors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m tqdm(points, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssign Labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m) :\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# color = knn_with_confidence_within_radius(d, point, tree, seg_colors, seg_logits, unique_labels)\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     color \u001b[38;5;241m=\u001b[39m \u001b[43mknn_with_confidence_within_radius\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_colors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     colors\u001b[38;5;241m.\u001b[39mappend( color)\n",
      "Cell \u001b[0;32mIn[2], line 348\u001b[0m, in \u001b[0;36mknn_with_confidence_within_radius\u001b[0;34m(radius, location, tree, colors, logits, unique_labels, useMean)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# for label, confidential in zip(labels, confidentials):\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m#     # Find the index of the label in unique_labels\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m#     idx = np.where(np.all(unique_labels == label, axis=1))[0]\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m#     if idx.size > 0:\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m#         results[idx[0]] += confidential[0]\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, unique_label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unique_labels):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Find all rows in labels that match the current unique_label\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43munique_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(matches):  \u001b[38;5;66;03m# Check if there are any matches\u001b[39;00m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;66;03m# Sum the corresponding confidential values\u001b[39;00m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m useMean:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ks= [500,600,700,800,900,1000]\n",
    "# ks=[500]\n",
    "dis = [0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "history_time = []\n",
    "for d in dis:\n",
    "    args.radius = d\n",
    "    print('set radius to ', d)\n",
    "    \n",
    "    for model in models:\n",
    "        start_time = time.time()\n",
    "        print(\"Processsing model {}\".format(model))\n",
    "        id = model.split(os.sep)[-2]\n",
    "        model_point_cloud = read_point_cloud(model)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        points \n",
    "        points -= points.mean(0)\n",
    "        model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                            [0,1,0,0],\n",
    "                            [0,0,1,0],\n",
    "                            [0,0,0,1]]))\n",
    "        recenter_model(model_point_cloud)\n",
    "        ############ 2D to 3D Reprojection #############\n",
    "        \n",
    "        pcds = []\n",
    "        logits = []\n",
    "        for i in range(10):\n",
    "            view_path = os.path.join(args.mask_input_path, f\"{id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            logit_path = os.path.join(args.mask_input_path, f'{id}_image{i+1}_cdcl_seg_output.npy')\n",
    "            depth_path = os.path.join(args.depth_input_path, f\"{id}_depth{i+1}.npy\")\n",
    "            extrinsic_path = os.path.join(args.extrinsic_input_path, f\"{id}_extrinsic{i+1}.npy\")\n",
    "            rgbd_image_seg = read_segmentation2(view_path=view_path, depth_path=depth_path)\n",
    "            logit = read_logits(view_path=logit_path, depth_path=depth_path)\n",
    "            \n",
    "            print(f\"{id} get view from {id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            pcd = rgbd_to_pointcloud2(rgbd_image_seg, intrinsic, extrinsic_path)   \n",
    "            logit = rgbd_to_pointcloud2(logit, intrinsic, extrinsic_path)     \n",
    "            pcds.append(pcd)\n",
    "            logits.append(logit)\n",
    "        assert(len(pcds) == args.num_views)\n",
    "\n",
    "        Pcd_merged = (reduce(lambda x, y: x + y, pcds))\n",
    "        path = os.path.join(args.output_path, 'raw')\n",
    "        # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "        o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_.ply'),Pcd_merged )\n",
    "        render([Pcd_merged])\n",
    "        logits_merged = reduce(lambda x, y: x + y, logits)\n",
    "        seg_points = np.asarray(Pcd_merged.points)\n",
    "        tree = cKDTree(seg_points)\n",
    "\n",
    "        seg_colors = np.asarray(Pcd_merged.colors)\n",
    "        seg_logits = np.asarray(logits_merged.colors)\n",
    "        # print(np.max(seg_logits))\n",
    "        unique_labels,_ = np.unique(seg_colors, axis=0, return_counts=True)\n",
    "        # print(unique_labels)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Assign Labels\", unit=\"point\") :\n",
    "            # color = knn_with_confidence_within_radius(d, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            color = knn_with_confidence_within_radius(args.radius, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        # smoothing\n",
    "        points = np.asarray(pcd_result.points)\n",
    "        seg_colors = np.asarray(pcd_result.colors)\n",
    "        tree = cKDTree(points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Processing\", unit=\"point\") :\n",
    "            color = knn(args.smooth, point, tree, seg_colors)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_used = (int) (end_time - start_time)\n",
    "        print('time used:', time_used)\n",
    "        history_time.append(time_used)\n",
    "        # render([pcd_result])\n",
    "        path = os.path.join(args.output_path, 'radius+useMean+backgroundThreshold+smooth')\n",
    "        # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "        o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{args.radius}_{args.smooth}_result_{time_used}.ply'),pcd_result )\n",
    "        # print(f\"{id} result point cloud output to {args.output_path}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set radius to  0.03\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [05:13<00:00, 2553.04point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:11<00:00, 11253.50point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 387\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [05:24<00:00, 2462.84point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:11<00:00, 11265.21point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 398\n",
      "set radius to  0.04\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [08:20<00:00, 1597.14point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:11<00:00, 11238.50point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 574\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [08:39<00:00, 1539.76point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:10<00:00, 11274.20point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 593\n",
      "set radius to  0.05\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [12:23<00:00, 1075.35point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:11<00:00, 11197.60point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 818\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [12:54<00:00, 1032.92point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:10<00:00, 11285.58point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 848\n",
      "set radius to  0.06\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [17:27<00:00, 763.71point/s] \n",
      "Processing: 100%|██████████| 799951/799951 [01:11<00:00, 11260.59point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1121\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [18:11<00:00, 733.23point/s] \n",
      "Processing: 100%|██████████| 799964/799964 [01:11<00:00, 11245.46point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1165\n",
      "set radius to  0.07\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [23:30<00:00, 567.33point/s] \n",
      "Processing: 100%|██████████| 799951/799951 [01:11<00:00, 11216.96point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1484\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [24:29<00:00, 544.33point/s] \n",
      "Processing: 100%|██████████| 799964/799964 [01:10<00:00, 11386.36point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1542\n"
     ]
    }
   ],
   "source": [
    "ks= [500,600,700,800,900,1000]\n",
    "# ks=[500]\n",
    "dis = [0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "history_time = []\n",
    "for d in dis:\n",
    "    args.radius = d\n",
    "    print('set radius to ', d)\n",
    "    \n",
    "    for model in models:\n",
    "        start_time = time.time()\n",
    "        print(\"Processsing model {}\".format(model))\n",
    "        id = model.split(os.sep)[-2]\n",
    "        model_point_cloud = read_point_cloud(model)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        points \n",
    "        points -= points.mean(0)\n",
    "        model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                            [0,1,0,0],\n",
    "                            [0,0,1,0],\n",
    "                            [0,0,0,1]]))\n",
    "        recenter_model(model_point_cloud)\n",
    "        ############ 2D to 3D Reprojection #############\n",
    "        \n",
    "        pcds = []\n",
    "        logits = []\n",
    "        for i in range(10):\n",
    "            view_path = os.path.join(args.mask_input_path, f\"{id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            logit_path = os.path.join(args.mask_input_path, f'{id}_image{i+1}_cdcl_seg_output.npy')\n",
    "            depth_path = os.path.join(args.depth_input_path, f\"{id}_depth{i+1}.npy\")\n",
    "            extrinsic_path = os.path.join(args.extrinsic_input_path, f\"{id}_extrinsic{i+1}.npy\")\n",
    "            rgbd_image_seg = read_segmentation2(view_path=view_path, depth_path=depth_path)\n",
    "            logit = read_logits(view_path=logit_path, depth_path=depth_path)\n",
    "            \n",
    "            print(f\"{id} get view from {id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            pcd = rgbd_to_pointcloud2(rgbd_image_seg, intrinsic, extrinsic_path)   \n",
    "            logit = rgbd_to_pointcloud2(logit, intrinsic, extrinsic_path)     \n",
    "            pcds.append(pcd)\n",
    "            logits.append(logit)\n",
    "        assert(len(pcds) == args.num_views)\n",
    "\n",
    "        Pcd_merged = (reduce(lambda x, y: x + y, pcds))\n",
    "        # render([Pcd_merged])\n",
    "        logits_merged = reduce(lambda x, y: x + y, logits)\n",
    "        seg_points = np.asarray(Pcd_merged.points)\n",
    "        tree = cKDTree(seg_points)\n",
    "\n",
    "        seg_colors = np.asarray(Pcd_merged.colors)\n",
    "        seg_logits = np.asarray(logits_merged.colors)\n",
    "        # print(np.max(seg_logits))\n",
    "        unique_labels,_ = np.unique(seg_colors, axis=0, return_counts=True)\n",
    "        # print(unique_labels)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Assign Labels\", unit=\"point\") :\n",
    "            # color = knn_with_confidence_within_radius(d, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            color = knn_with_confidence_within_radius(args.radius, point, tree, seg_colors, seg_logits, unique_labels, useMean=False)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        # smoothing\n",
    "        points = np.asarray(pcd_result.points)\n",
    "        seg_colors = np.asarray(pcd_result.colors)\n",
    "        tree = cKDTree(points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Processing\", unit=\"point\") :\n",
    "            color = knn(args.smooth, point, tree, seg_colors)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_used = (int) (end_time - start_time)\n",
    "        print('time used:', time_used)\n",
    "        history_time.append(time_used)\n",
    "        # render([pcd_result])\n",
    "        path = os.path.join(args.output_path, 'radius+useSum+backgroundThreshold+smooth')\n",
    "        # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "        o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{args.radius}_{args.smooth}_result_{time_used}.ply'),pcd_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set radius to  0.03\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [05:32<00:00, 2405.76point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:10<00:00, 11286.51point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 406\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [05:45<00:00, 2316.18point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:11<00:00, 11256.71point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 419\n",
      "set radius to  0.04\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [08:48<00:00, 1512.73point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:10<00:00, 11298.12point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 602\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [09:11<00:00, 1449.22point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:11<00:00, 11203.74point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 626\n",
      "set radius to  0.05\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [13:06<00:00, 1017.45point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:11<00:00, 11266.76point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 860\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [13:40<00:00, 974.99point/s] \n",
      "Processing: 100%|██████████| 799964/799964 [01:10<00:00, 11308.03point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 894\n",
      "set radius to  0.06\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [18:29<00:00, 721.32point/s] \n",
      "Processing: 100%|██████████| 799951/799951 [01:10<00:00, 11333.95point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1182\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [19:18<00:00, 690.65point/s] \n",
      "Processing: 100%|██████████| 799964/799964 [01:10<00:00, 11340.96point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1231\n",
      "set radius to  0.07\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [25:09<00:00, 529.78point/s] \n",
      "Processing: 100%|██████████| 799951/799951 [01:12<00:00, 11047.00point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1585\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [27:47<00:00, 479.86point/s] \n",
      "Processing: 100%|██████████| 799964/799964 [01:17<00:00, 10265.73point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 1748\n"
     ]
    }
   ],
   "source": [
    "ks= [500,600,700,800,900,1000]\n",
    "dis = [0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "history_time = []\n",
    "for d in dis:\n",
    "    args.radius = d\n",
    "    print('set radius to ', d)\n",
    "    \n",
    "    for model in models:\n",
    "        start_time = time.time()\n",
    "        print(\"Processsing model {}\".format(model))\n",
    "        id = model.split(os.sep)[-2]\n",
    "        model_point_cloud = read_point_cloud(model)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        points \n",
    "        points -= points.mean(0)\n",
    "        model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                            [0,1,0,0],\n",
    "                            [0,0,1,0],\n",
    "                            [0,0,0,1]]))\n",
    "        recenter_model(model_point_cloud)\n",
    "        ############ 2D to 3D Reprojection #############\n",
    "        \n",
    "        pcds = []\n",
    "        logits = []\n",
    "        for i in range(10):\n",
    "            view_path = os.path.join(args.mask_input_path, f\"{id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            logit_path = os.path.join(args.mask_input_path, f'{id}_image{i+1}_cdcl_seg_output.npy')\n",
    "            depth_path = os.path.join(args.depth_input_path, f\"{id}_depth{i+1}.npy\")\n",
    "            extrinsic_path = os.path.join(args.extrinsic_input_path, f\"{id}_extrinsic{i+1}.npy\")\n",
    "            rgbd_image_seg = read_segmentation2(view_path=view_path, depth_path=depth_path)\n",
    "            logit = read_logits(view_path=logit_path, depth_path=depth_path)\n",
    "            \n",
    "            print(f\"{id} get view from {id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            pcd = rgbd_to_pointcloud2(rgbd_image_seg, intrinsic, extrinsic_path)   \n",
    "            logit = rgbd_to_pointcloud2(logit, intrinsic, extrinsic_path)     \n",
    "            pcds.append(pcd)\n",
    "            logits.append(logit)\n",
    "        assert(len(pcds) == args.num_views)\n",
    "\n",
    "        Pcd_merged = (reduce(lambda x, y: x + y, pcds))\n",
    "        # render([Pcd_merged])\n",
    "        logits_merged = reduce(lambda x, y: x + y, logits)\n",
    "        seg_points = np.asarray(Pcd_merged.points)\n",
    "        tree = cKDTree(seg_points)\n",
    "\n",
    "        seg_colors = np.asarray(Pcd_merged.colors)\n",
    "        seg_logits = np.asarray(logits_merged.colors)\n",
    "        # print(np.max(seg_logits))\n",
    "        unique_labels,_ = np.unique(seg_colors, axis=0, return_counts=True)\n",
    "        # print(unique_labels)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Assign Labels\", unit=\"point\") :\n",
    "            # color = knn_with_confidence_within_radius(d, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            color = knn_with_confidence_within_radius_weighted_mean_count(args.radius, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        # smoothing\n",
    "        points = np.asarray(pcd_result.points)\n",
    "        seg_colors = np.asarray(pcd_result.colors)\n",
    "        tree = cKDTree(points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Processing\", unit=\"point\") :\n",
    "            color = knn(args.smooth, point, tree, seg_colors)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_used = (int) (end_time - start_time)\n",
    "        print('time used:', time_used)\n",
    "        history_time.append(time_used)\n",
    "        # render([pcd_result])\n",
    "        path = os.path.join(args.output_path, 'radius+weighted+backgroundThreshold+smooth')\n",
    "        # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "        o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{args.radius}_{args.smooth}_result_{time_used}.ply'),pcd_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set k to  500\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [03:55<00:00, 3390.78point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:11<00:00, 11225.62point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 313\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [04:01<00:00, 3315.74point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:09<00:00, 11437.57point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 318\n",
      "set k to  800\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [05:29<00:00, 2431.09point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:10<00:00, 11310.37point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 404\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [05:19<00:00, 2502.55point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:08<00:00, 11691.10point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 392\n",
      "set k to  1000\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [06:19<00:00, 2109.31point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:08<00:00, 11657.29point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 451\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [06:14<00:00, 2137.58point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:07<00:00, 11776.12point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 446\n",
      "set k to  1200\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [07:15<00:00, 1838.43point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:06<00:00, 11966.81point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 505\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [07:07<00:00, 1872.20point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:06<00:00, 12020.38point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 498\n",
      "set k to  1500\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [08:27<00:00, 1576.26point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:06<00:00, 11982.77point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 578\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [08:28<00:00, 1572.70point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:06<00:00, 12038.10point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 578\n",
      "set k to  1700\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [09:27<00:00, 1409.37point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:07<00:00, 11935.71point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 637\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [09:25<00:00, 1413.50point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:06<00:00, 12012.53point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 635\n",
      "set k to  2000\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [11:20<00:00, 1175.21point/s]\n",
      "Processing: 100%|██████████| 799951/799951 [01:12<00:00, 10973.98point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 756\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [11:23<00:00, 1170.03point/s]\n",
      "Processing: 100%|██████████| 799964/799964 [01:11<00:00, 11155.36point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 763\n"
     ]
    }
   ],
   "source": [
    "ks= [500, 800, 1000, 1200, 1500, 1700, 2000]\n",
    "dis = [0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "history_time = []\n",
    "for k in ks:\n",
    "    args.k = k\n",
    "    print('set k to ', k)\n",
    "    \n",
    "    for model in models:\n",
    "        start_time = time.time()\n",
    "        print(\"Processsing model {}\".format(model))\n",
    "        id = model.split(os.sep)[-2]\n",
    "        model_point_cloud = read_point_cloud(model)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        points \n",
    "        points -= points.mean(0)\n",
    "        model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                            [0,1,0,0],\n",
    "                            [0,0,1,0],\n",
    "                            [0,0,0,1]]))\n",
    "        recenter_model(model_point_cloud)\n",
    "        ############ 2D to 3D Reprojection #############\n",
    "        \n",
    "        pcds = []\n",
    "        logits = []\n",
    "        for i in range(10):\n",
    "            view_path = os.path.join(args.mask_input_path, f\"{id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            logit_path = os.path.join(args.mask_input_path, f'{id}_image{i+1}_cdcl_seg_output.npy')\n",
    "            depth_path = os.path.join(args.depth_input_path, f\"{id}_depth{i+1}.npy\")\n",
    "            extrinsic_path = os.path.join(args.extrinsic_input_path, f\"{id}_extrinsic{i+1}.npy\")\n",
    "            rgbd_image_seg = read_segmentation2(view_path=view_path, depth_path=depth_path)\n",
    "            logit = read_logits(view_path=logit_path, depth_path=depth_path)\n",
    "            \n",
    "            print(f\"{id} get view from {id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            pcd = rgbd_to_pointcloud2(rgbd_image_seg, intrinsic, extrinsic_path)   \n",
    "            logit = rgbd_to_pointcloud2(logit, intrinsic, extrinsic_path)     \n",
    "            pcds.append(pcd)\n",
    "            logits.append(logit)\n",
    "        assert(len(pcds) == args.num_views)\n",
    "\n",
    "        Pcd_merged = (reduce(lambda x, y: x + y, pcds))\n",
    "        # render([Pcd_merged])\n",
    "        logits_merged = reduce(lambda x, y: x + y, logits)\n",
    "        seg_points = np.asarray(Pcd_merged.points)\n",
    "        tree = cKDTree(seg_points)\n",
    "\n",
    "        seg_colors = np.asarray(Pcd_merged.colors)\n",
    "        seg_logits = np.asarray(logits_merged.colors)\n",
    "        # print(np.max(seg_logits))\n",
    "        unique_labels,_ = np.unique(seg_colors, axis=0, return_counts=True)\n",
    "        # print(unique_labels)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Assign Labels\", unit=\"point\") :\n",
    "            # color = knn_with_confidence_within_radius(d, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            color = knn_with_confidence(args.k, point, tree, seg_colors, seg_logits, unique_labels, useMean=True)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        # smoothing\n",
    "        points = np.asarray(pcd_result.points)\n",
    "        seg_colors = np.asarray(pcd_result.colors)\n",
    "        tree = cKDTree(points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Processing\", unit=\"point\") :\n",
    "            color = knn(args.smooth, point, tree, seg_colors)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_used = (int) (end_time - start_time)\n",
    "        print('time used:', time_used)\n",
    "        history_time.append(time_used)\n",
    "        # render([pcd_result])\n",
    "        path = os.path.join(args.output_path, 'k+useMean+backgroundThreshold+smooth')\n",
    "        # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "        o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{args.k}_{args.smooth}_result_{time_used}.ply'),pcd_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set k to  2100\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [11:46<00:00, 1131.84point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 708\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [11:54<00:00, 1119.04point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 717\n",
      "set k to  2200\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [12:07<00:00, 1098.90point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 731\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [12:10<00:00, 1094.81point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 735\n",
      "set k to  2150\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0500/pcd_0.ply\n",
      "0500 get view from 0500_image1_cdcl_segmask.npy\n",
      "0500 get view from 0500_image2_cdcl_segmask.npy\n",
      "0500 get view from 0500_image3_cdcl_segmask.npy\n",
      "0500 get view from 0500_image4_cdcl_segmask.npy\n",
      "0500 get view from 0500_image5_cdcl_segmask.npy\n",
      "0500 get view from 0500_image6_cdcl_segmask.npy\n",
      "0500 get view from 0500_image7_cdcl_segmask.npy\n",
      "0500 get view from 0500_image8_cdcl_segmask.npy\n",
      "0500 get view from 0500_image9_cdcl_segmask.npy\n",
      "0500 get view from 0500_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799951/799951 [12:20<00:00, 1079.99point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 745\n",
      "Processsing model /home/demoy/3dProjection/THuman2.0 Samples-20231208T170459Z-001/THuman2.0 Samples/0501/pcd_0.ply\n",
      "0501 get view from 0501_image1_cdcl_segmask.npy\n",
      "0501 get view from 0501_image2_cdcl_segmask.npy\n",
      "0501 get view from 0501_image3_cdcl_segmask.npy\n",
      "0501 get view from 0501_image4_cdcl_segmask.npy\n",
      "0501 get view from 0501_image5_cdcl_segmask.npy\n",
      "0501 get view from 0501_image6_cdcl_segmask.npy\n",
      "0501 get view from 0501_image7_cdcl_segmask.npy\n",
      "0501 get view from 0501_image8_cdcl_segmask.npy\n",
      "0501 get view from 0501_image9_cdcl_segmask.npy\n",
      "0501 get view from 0501_image10_cdcl_segmask.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assign Labels: 100%|██████████| 799964/799964 [12:22<00:00, 1077.86point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 746\n"
     ]
    }
   ],
   "source": [
    "ks= [2100, 2200, 2150]\n",
    "dis = [0.03, 0.04, 0.05, 0.06, 0.07]\n",
    "\n",
    "history_time = []\n",
    "for k in ks:\n",
    "    args.k = k\n",
    "    print('set k to ', k)\n",
    "    # args.smooth = 500\n",
    "    for model in models:\n",
    "        start_time = time.time()\n",
    "        print(\"Processsing model {}\".format(model))\n",
    "        id = model.split(os.sep)[-2]\n",
    "        model_point_cloud = read_point_cloud(model)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        points \n",
    "        points -= points.mean(0)\n",
    "        model_point_cloud.transform(np.array([[1,0,0,0], \n",
    "                            [0,1,0,0],\n",
    "                            [0,0,1,0],\n",
    "                            [0,0,0,1]]))\n",
    "        recenter_model(model_point_cloud)\n",
    "        ############ 2D to 3D Reprojection #############\n",
    "        \n",
    "        pcds = []\n",
    "        logits = []\n",
    "        for i in range(10):\n",
    "            view_path = os.path.join(args.mask_input_path, f\"{id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            logit_path = os.path.join(args.mask_input_path, f'{id}_image{i+1}_cdcl_seg_output.npy')\n",
    "            depth_path = os.path.join(args.depth_input_path, f\"{id}_depth{i+1}.npy\")\n",
    "            extrinsic_path = os.path.join(args.extrinsic_input_path, f\"{id}_extrinsic{i+1}.npy\")\n",
    "            rgbd_image_seg = read_segmentation2(view_path=view_path, depth_path=depth_path)\n",
    "            logit = read_logits(view_path=logit_path, depth_path=depth_path)\n",
    "            \n",
    "            print(f\"{id} get view from {id}_image{i+1}_cdcl_segmask.npy\")\n",
    "            pcd = rgbd_to_pointcloud2(rgbd_image_seg, intrinsic, extrinsic_path)   \n",
    "            logit = rgbd_to_pointcloud2(logit, intrinsic, extrinsic_path)     \n",
    "            pcds.append(pcd)\n",
    "            logits.append(logit)\n",
    "        assert(len(pcds) == args.num_views)\n",
    "\n",
    "        Pcd_merged = (reduce(lambda x, y: x + y, pcds))\n",
    "        # render([Pcd_merged])\n",
    "        logits_merged = reduce(lambda x, y: x + y, logits)\n",
    "        seg_points = np.asarray(Pcd_merged.points)\n",
    "        tree = cKDTree(seg_points)\n",
    "\n",
    "        seg_colors = np.asarray(Pcd_merged.colors)\n",
    "        seg_logits = np.asarray(logits_merged.colors)\n",
    "        # print(np.max(seg_logits))\n",
    "        unique_labels,_ = np.unique(seg_colors, axis=0, return_counts=True)\n",
    "        # print(unique_labels)\n",
    "        points = np.asarray(model_point_cloud.points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Assign Labels\", unit=\"point\") :\n",
    "            # color = knn_with_confidence_within_radius(d, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            # color = knn_with_confidence_weighted_mean_count(args.k, point, tree, seg_colors, seg_logits, unique_labels)\n",
    "            color = knn_with_confidence(K=args.k, location=point, tree=tree, colors=seg_colors, logits=seg_logits, unique_labels=unique_labels, useMean=False)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        # smoothing\n",
    "        # points = np.asarray(pcd_result.points)\n",
    "        # seg_colors = np.asarray(pcd_result.colors)\n",
    "        # tree = cKDTree(points)\n",
    "        # colors = []\n",
    "        # for point in tqdm(points, desc=\"Processing\", unit=\"point\") :\n",
    "        #     color = knn(args.smooth, point, tree, seg_colors)\n",
    "        #     # break\n",
    "        #     colors.append( color)\n",
    "            \n",
    "        # colors_stacked = np.vstack(colors)\n",
    "\n",
    "        # pcd_result = o3d.geometry.PointCloud()\n",
    "        # pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        # pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_used = (int) (end_time - start_time)\n",
    "        print('time used:', time_used)\n",
    "        history_time.append(time_used)\n",
    "        # render([pcd_result])\n",
    "        path = os.path.join(args.output_path, 'k+useSum+backgroundThreshold+smooth')\n",
    "        # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "        o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{args.k}_0_result_{time_used}.ply'),pcd_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set smooth to  400\n",
      "work on 0501_cdcl_pcd_2200_0_result_735.ply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 799964/799964 [02:43<00:00, 4886.02point/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set smooth to  500\n",
      "work on 0501_cdcl_pcd_2200_0_result_735.ply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 799964/799964 [03:09<00:00, 4212.05point/s]\n"
     ]
    }
   ],
   "source": [
    "# smooth = [100,200,300,400, 500]\n",
    "# pointclouds = [f'/home/demoy/3dProjection/confidence_search/k+weighted+backgroundThreshold+smooth/0500_cdcl_pcd_2100_0_result_753.ply', \n",
    "#                f'/home/demoy/3dProjection/confidence_search/k+weighted+backgroundThreshold+smooth/0500_cdcl_pcd_2150_0_result_762.ply',\n",
    "#                f'/home/demoy/3dProjection/confidence_search/k+weighted+backgroundThreshold+smooth/0500_cdcl_pcd_2200_0_result_776.ply',\n",
    "#                f'/home/demoy/3dProjection/confidence_search/k+weighted+backgroundThreshold+smooth/0501_cdcl_pcd_2100_0_result_748.ply',\n",
    "#                f'/home/demoy/3dProjection/confidence_search/k+weighted+backgroundThreshold+smooth/0501_cdcl_pcd_2150_0_result_768.ply',\n",
    "#                f'/home/demoy/3dProjection/confidence_search/k+weighted+backgroundThreshold+smooth/0501_cdcl_pcd_2200_0_result_786.ply']\n",
    "\n",
    "smooth = [400, 500]\n",
    "pointclouds = [f'/home/demoy/3dProjection/confidence_search/k+useSum+backgroundThreshold+smooth/0501_cdcl_pcd_2200_0_result_735.ply']\n",
    "for s in smooth:\n",
    "    print('set smooth to ', s)\n",
    "    for pd in pointclouds:\n",
    "        \n",
    "        filename = os.path.basename(pd)\n",
    "        print(f'work on {filename}')\n",
    "        filename = os.path.splitext(filename)[0]\n",
    "        \n",
    "        fileargs = filename.split('_')\n",
    "        timeused = fileargs[-1]\n",
    "        k = fileargs[3]\n",
    "        id = fileargs[0]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        pcd_result = read_point_cloud(pd)\n",
    "        points = np.asarray(pcd_result.points)\n",
    "        seg_colors = np.asarray(pcd_result.colors)\n",
    "        tree = cKDTree(points)\n",
    "        colors = []\n",
    "        for point in tqdm(points, desc=\"Processing\", unit=\"point\") :\n",
    "            color = knn(s, point, tree, seg_colors)\n",
    "            # break\n",
    "            colors.append( color)\n",
    "            \n",
    "        colors_stacked = np.vstack(colors)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        total_time = end_time-start_time+float(timeused)\n",
    "        total_time = int(total_time)\n",
    "        pcd_result = o3d.geometry.PointCloud()\n",
    "        pcd_result.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd_result.colors = o3d.utility.Vector3dVector(colors_stacked)\n",
    "        path = os.path.join(args.output_path, 'k+weighted+backgroundThreshold+smooth')\n",
    "            # o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{d}_result_{time_used}.ply'),pcd_result )\n",
    "        o3d.io.write_point_cloud(os.path.join(path,f'{id}_cdcl_pcd_{k}_{s}_result_{total_time}.ply'),pcd_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = read_point_cloud(f'/home/demoy/3dProjection/confidence_search/raw/0501_cdcl_pcd_.ply')\n",
    "\n",
    "render([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "k = 400\n",
    "t = read_point_cloud(f'/home/demoy/3dProjection/confidence_search/useMean/0500_cdcl_pcd_500_result.ply')\n",
    "\n",
    "render([t])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
